import os
from flask import Flask, request, jsonify, render_template
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import pickle
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import re

nltk.download('stopwords', download_dir='/tmp')
nltk.download('punkt', download_dir='/tmp')

TEMPLATE_DIR = os.path.abspath('../templates')
STATIC_DIR = os.path.abspath('../static')

application = Flask(__name__)
app = application

# Import the vectorizer and trained model
# vectorizer = pickle.load(open("models/vectorizer.pkl", "rb"))
trained_model = pickle.load(open("models/modelPred.pkl", "rb"))

stop_words = set(stopwords.words('english'))

def remove_stop_words(text):
    tokens = word_tokenize(text)
    filt_text = [word for word in tokens if word.lower() not in stop_words]
    return ' '.join (filt_text)

def remove_special_char(text):
    pattern = r'[^\w\s]|[\n\t\r]'
    return re.sub(pattern, '', text)


@app.route("/", methods=['GET', 'POST'])
def index():
    if (request.method == 'POST'):
        data = [str(request.form.get('inputText'))]
        df = pd.DataFrame({'text': data})
        df['text'] = df['text'].apply(remove_special_char)
        df['text'] = df['text'].apply(remove_stop_words)
        val = trained_model.predict(df['text'])
        val = "The entered text is generated by AI" if val[0] == 1 else "The entered text is written by Human"

        return render_template('index.html', results=val, textContent=data[0])

    else:
        return render_template("index.html")

if __name__ == "__main__":
    app.run(host="0.0.0.0")